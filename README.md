# web_crawler
This web crawler is particularly used for crawling the information from websites and save it into html, and then transfer to pdf. After that, remove the htmls.

Required libraries for this web crawler: requests, beautifulsoup4, and pdfkit
(scrapy can be used for more complicated crawlers)
(1)reuqests is used for http requests
(2)beautifusoup is used for parsing html, 
(3)wkhtmltopdf can be used for transfering html to pdf (url to pdf, etc)ï¼Œpdfkit is a package from wkhtmltopdf

steps of installing these libraries
s1: pip3 install requests
s2: pip3 install beautifulsoup4 (this can only be used for python3)
s3: pip3 install pdfkit
s4: pip3 install wkhtmltopdf
